# ALGORITMOS PREDITIVOS {-}

## K-vizinhos mais próximos {-}

O algoritmo de K-vizinhos mais próximos ou KNN(*k-nearest neighbors*) é um tipo
de algoritmo de aprendizado de máquina baseado em exemplos ou instâncias. Isso
significa que, invés de estimar algum parâmetro para realizar predições cada
vez mais precisas, ele realiza um processo de "memorização" baseado em algum
critério de similaridade entre as instâncias do conjunto de dados[@de2019machine].

```{r fig.cap = "Ilustração do algoritmo KNN",fig.align = 'center',echo = FALSE}
knitr::include_graphics(rep("figuras/knn.png"))
```

O seu funcionamento consiste em escolher um número K de vizinhos mais próximos 
para realizar a predição.Definido a quantidade, o algoritmo irá percorrer todo
o conjunto de dados procurando os k mais próximos. Por fim, caso o algoritmo
seja usado para classificação, irá ser feito pela classe mais frequente, ou seja
voto majoritário, caso seja usado para regressão, será computado a média dos k
vizinhos mais próximos:

---

**Algoritmo 1**:  K vizinhos mais próximos para $K = 1$

---

| **Inicialize** $D$: $D = \{(x^{(1)}, y^{(1)}),...,(x^{(n)},y^{(n)})\}$

| **Inicialize** $x^{(P)}$: Sendo $x^{(P)}$ como a instância para predição.

| **Inicialize** $d$ : $d(x^{(i)},x^{(p)})$ como a medida de similaridade. 

| instancia_perto = $none$

| distancia_mais_proxima = $\infty$

| rotulo_perto = $none$

| **Para** $i = 1,...,n$ **faça**:

|    distancia = $d(x^{(i)},x^{(p)})$

|    **Se** distancia $\leq$ distancia_mais_proxima **então**:
    
|        distancia_mais_proxima = distancia
      
|        instancia_perto = $x^{(i)}$

|        rotulo_perto = $y^{(i)}$

| **retorne** rotulo_perto

---

Observe abaixo exemplos de medidas de similaridade comumente utilizas no algoritmo:

$$\begin{equation}
d_{E}(\vec{x}, \vec{y}) = \sqrt{\sum_{i = 1}^{n}(\vec{x_{i}} -\vec{y_{i}})^{2}}
(\#eq:euclidiana)
\end{equation}$$

$$\begin{equation}
d_{M}(\vec{x}, \vec{y}) = \sum_{i = 1}^{n} | \vec{x_{i}} - \vec{y_{i}}|
(\#eq:manhattan)
\end{equation}$$


## Árvore de decisão {-}

A árvore de decisão é um método de aprendizado simbólico que é usado tanto para
a classificação quanto para a regressão.

O funcionamento de uma árvore de decisão em um problema de classificação 
consiste em criar partições em seu  conjunto de dados de modo que deixe os 
dados homogêneos em relação a seus rótulos. Primeiro defini-se atributos que 
sirvam como critérios para divisão também chamados de nós das árvores, e os nós 
finais onde não é possível dividir são chamados de nós de folhas[@quinlan1986induction].

```{r fig.cap = "Ilustração de uma árvore de decisão",fig.align = 'center',echo = FALSE}
knitr::include_graphics(rep("figuras/arvore_decisao.png"))
```

As árvores de decisão são bastante populares no campo do aprendizado de máquina,
possuindo bom desempenho e robustez a dados não escalonados, todavia ela é propensa
a sobreajuste isto é, quando ela possui um desempenho satisfatório nos dados de
treino, todavia não é refletido nos dados de teste. Observe abaixo as principais
medidas utilizadas para calcular a homogeneidade dos dados: 

---

**Algoritmo 2**:  Árvore de decisão binária simples 

---

| **Inicialize** $D$: $D = \{(x^{(1)}, y^{(1)}),...,(x^{(n)},y^{(n)})\} \forall y \in {0,1}$

| **Inicialize** $Xi$: Melhor Atributo para divisão dos dados 

|    GerarArvore($D$):

|        Se $y = 1$ ou $y = 0$ $\forall  y \subset D$:

|            **retorne** Árvore

|        Senão:

|            $Xi = pegarMelhorAtributo(D)$

|            $D_{0} = DividirDados(Xi)$    

|            $D_{1} = DividirDados(Xi)$

|        **retorne** $Nó(Xi,GerarArvore(D_{0}),GerarArvore(D_{1}))$

---

Observe abaixo as medidas utilizas para identificar o melhor atributo:

$$\begin{equation}
gini = 1 - \sum_{i = 1}^{c}(p_{i})^{2}
(\#eq:gini)
\end{equation}$$

$$\begin{equation}
ganho = Entropia(S) - \sum_{v \in A} \frac{|S_{v}|}{|S|} . Entropia(S_{v})
(\#eq:ganho)
\end{equation}$$

$$\begin{equation}
entropia = - \sum_{i = 1}^{C}(p_{i})log{_2}{(p_{i})}
(\#eq:entropia)
\end{equation}$$

Sendo:

- $p_{i}$: Probabilidade da classe;
- $S$: Coluna dos rótulos;
- $C$: Número de classes distintas;
- $A$: Elementos distintos de uma coluna;

## *Suport Vector Machine*(Máquinas de vetores de suporte) {-}

A SVM(*Suport Vector Machine*) é um algoritmo amplamente utilizado no aprendizado
de máquina, tanto para a classificação quanto para a regressão. Seu funcionamento
consistem em criar um hiperplano que melhor separe os dados ou seja, um hiperplano
que maximize a margem entre os dados, para isso o algoritmo utiliza-se de dados
auxiliares chamados de vetores de suporte, que ficam nos limites das margens[@Boser92atraining]:

```{r fig.cap = "Ilustração de uma máquina de vetores de suporte",fig.align = 'center',echo = FALSE}
knitr::include_graphics(rep("figuras/svm.png"))
```


$$\begin{equation}
 w_{*} = \arg \min_{w} \frac{1}{2} ||w||^{2} + C \sum_{i}\xi_{i} 
 (\#eq:svm)
\end{equation}$$

As SVMs possuem duas abordagens: *Soft Margin* e *Hard Margin*. A *Hard Margin*
nada mais é do que ajustar o hiperplano para separar os dados sem tolerar nenhum
erro do modelo, isso significa que caso tenha alguma anomalia nos dados, a abordagem
*Hard Margin* continuará ajustando o hiperplano, o que pode ocasionar em um sobreajuste.
Já a *soft margin* tolera que o algoritmo erre em alguns pontos. Como visto na 
equação acima o termo $C \sum_{i}\xi_{i}$ serve para o ponderamento em questão.
Valores muito altos na constante $C$ faz com que o algoritmo tolere menos os
erros, já valores pequenos há uma certa tolerância.

Como as SVMs trabalham apenas com dados linearmente separáveis, se faz necessárias
técnica para transformação desses dados. Essas técnicas são chamadas de *Kernel Tricks*
ou truque do *Kernel*. O que ele faz é elevar os nossos dados em dimensões maiores
o tornando linearmente separável:

- Linear: $<X,X^{`}>$

- Polinomial: $(\gamma<X,X^{`}> + r)^{d}$

- RBF: $exp(-\gamma||X - X^{`}||^{2})$

- Sigmoid: $Tanh(\gamma<X,X^{`}> + r)$

## Regressão Linear {-}

A regressão linear trata-se de um algoritmo do tipo supervisionado que lida com
a predição de valores contínuos. Ela basicamente descreve a relação entre uma ou
mais variáveis em um conjunto de dados:

$$\begin{equation}
ŷ = \beta_{0} + \beta_{1}X_{i1} + \beta_{2}X_{i2} + ... + \beta_{m}X_{mi} + e_{i}
(\#eq:reg)
\end{equation}$$
Os valores $(\beta_{0}, \beta_{1}, ... ,\beta_{m})$ são os coeficientes utilizados
para realizar o produto com cada atributo $(X_{1},X_{2},...,X_{m})$ sendo $m$ o
número de atributos e $n$ o número de observações. Para encontrar o melhor estimador, 
utiliza-se de técnicas que visam diminuir uma função de custo, esta tem como 
objetivo quantificar o erro do estimador. A função de cuso mais utilizada é o 
Erro Quadrático Médio:

$$\begin{equation}
MSE(ŷ,y) = \frac{1}{n} \sum_{i}(ŷ_{i} - y_{i})^{2}
(\#eq:erro)
\end{equation}$$

## Regressão Logística {-}

A regressão logística é um tipo especial de regressão que é utilizada no paradigma de
classificação. Seu funcionamento se dá baseando-se um uma função que retorna valores
situados entre 0 e 1 denominada função sigmoid[@de2019machine]:

$$\begin{equation}
z = \beta^{T} X
(\#eq:funcaoz)
\end{equation}$$

$$\begin{equation}
\sigma(z) = \frac{1}{1+e^{-z}}
(\#eq:sigma)
\end{equation}$$

o resultado de $z$ é passado para uma função $\sigma$ que retorna uma probabilidade
associada. Portanto a predição de $ŷ$ será:

$$\begin{equation}
ŷ = 
  \begin{cases}
      1, \sigma(z) \geq 0,5 \\
      0, \sigma(z) < 0,5 
  \end{cases}
(\#eq:pred)
\end{equation}$$


## *Naive Bayes* {-}

O algoritmo *Naive Bayes* ou também chamado de Bayes "ingênuo" é um algoritmo
de aprendizado de máquina utilizado na classificação. O seu funcionamento consiste
em utilizar o teorema de Thomas Bayes para a classificação de uma classe $y$ dado
os atributos $(X_{1},X_{2},..., X_{m})$. O adjetivo "ingênuo" é usado, pois deve-se
assumir que os atributos são independentes já que assim evita-se um modelo complexo
demais:

$$\begin{equation}
P(A|B) = \frac{P(B|A) * P(A)}{P(B)}
(\#eq:bayes)
\end{equation}$$
$$\begin{equation}
P(y|X_{1},X_{2},...,X_{m}) = \arg \max_{j = 1...k} \frac {\prod P(X_{1}|y)...P(X_{m}|y) * P(y)} {P(X_{1}) ... P(X_{m})}
(\#eq:naive)
\end{equation}$$

## Modelos *Ensemble* {-}

Os modelos em conjunto(*Ensemble*) são uma família de estimadores que possui
uma característica em comum, cada estimador é composto por um conjunto de estimadores. O processo
consiste em agregar um conjunto de estimadores para tomar uma decisão, o que pode
potencializar a capacidade de generalização do modelo.

### *Random Forest* {-}

O algoritmo *Random Forest* é composto por uma combinação de árvores de decisão,
onde cada decisão de cada árvore impacta na classificação final,isso significa que cada
árvore possui um voto  para decidir qual classe escolher,sendo essa técnica denominada *voting*.
No caso da regressão, é computada a média dos ramos de cada árvore[@ho1995random].

```{r fig.cap = "Ilustração de uma Random Forest",fig.align = 'center',echo = FALSE}
knitr::include_graphics(rep("figuras/random_forest.png"))
```

O *random forest* utiliza a técnica de *bagging* em seu funcionamento, isso significa
que antes de alimentar cada árvore de decisão, é feito uma reamostragem nas linhas
e colunas da base de dados, sendo o processo de amostragem *bootstrap* a mais utilizada. Isso
faz com que sejam mais robustas a sobreajuste em comparação a uma única árvore de decisão.


### *AdaBoost* {-}

O algoritmo *AdaBoost* utiliza a abordagem de *boosting* em sua composição, isso
significa que ele combina um conjunto de classificadores fracos(*weak learners*)
que juntos, criam um modelo robusto para processos de predição[@freund1999short]:

---

**Algoritmo 3**:  Algoritmo *AdaBoost* para classificação 

---

| **Inicialize:** $T$: número de classificadores fracos

| **Inicialize** $D$: $D = \{(x^{(1)}, y^{(1)}),...,(x^{(n)},y^{(n)})\}$

| **Inicialize** $w_{j}(i)$: $w_{j}(i) = \frac{1}{n}$, $i = 1,..,n, w \in R^{n}$ 

| **Para** $j = 1,..T$ **faça**:

|    $h_{j} = TreineClassificadorFraco(D,w_{j})$

|    $E_{j} = \sum_{i} w_{j}(i) 1(h_{j}(x) \neq y_{i})$

|    $\alpha_{j} = \frac{1}{2}log( \frac{(1-E_{j})}{E_{j}})$

|    $w_{j+1}(i) = \frac{w_{j}(i)}{\sum_{i}w_{j}(i)} . a(\alpha)$

|    $$\begin{equation}
      a(\alpha) = 
      \begin{cases}
      e^{-\alpha_{j}},  h_{j}(x) \neq y_{i} \\
      e^{\alpha_{j}}, h_{j}(x) = y_{i} 
      \end{cases}
      \end{equation}$$
      
| $h_{final} = sign(\sum_{i}^{T} \alpha_{i}h_{i}(x) )$
---

O funcionamento do *AdaBoost* consiste em criar pesos de acordo com cada linha
da base de dados. O valor inicial do peso será igual para todas as linhas da
base de dados: $w_{j}(i) = \frac{1}{n}$. Depois é criado um classificador
que possui um desempenho um pouco superior a um classificador aleatório, esse
tem o nome de aprendiz fraco(*weak learner*) que irá computar suas predições.
Feito isso, o próximo passo será calcular $\alpha_{j}$ com base em $E_{j}$ que computa
as instâncias que o aprendiz fraco errou. O $\alpha_{j}$ tem como objetivo ponderar
cada aprendiz fraco. Feito isso, o proximo passo consiste em atualizar cada peso
$w_{j}(i)$. Por fim é realizado as predições levando em consideração o parâmetro 
$\alpha_{j}$ em cada aprendiz fraco.

### *Gradient Boost* {-}

O algoritmo *Gradient Boost* é um classificador utilizado tanto na regressão, quanto
na classificação. Sua ideia é utilizar a técnica de descida do gradiente para 
computar os resíduos de um classificador anterior, para então alimentar o próximo.
Seu funcionamento se baseia na técnica de *boost*, usando uma sequência de classificadores
sendo alimentados pelo resíduos de seus predecessores[@friedman2001greedy]:

---

**Algoritmo 4**:  Algoritmo *Gradient Boost* com árvores de decisão para regressão 

---

| **Inicialize:** $T$: número de classificadores fracos

| **Inicialize** $D$: $D = \{(x^{(1)}, y^{(1)}),...,(x^{(n)},y^{(n)})\}$

| **Inicialize** $L$: $L(y^{(i)},h(x^{(i)}))$ 

| $h_{0} = \arg \min_{ŷ} \sum_{i = 1}^{n} L(y^{(i)},ŷ)$

| **Para** $t = 1,...,T$ **faça**:

|    $r_{i,t} = - \frac{\partial L(y^{(i)},h(x^{(i)}))}{\partial h(x^{(i)})}, para$ $i = 1,...,n$, $h(x^{(i)}) = h_{t-1}(x^{(i)})$

|    Treinar o novo modelo com os resíduos $r_{i,t}$ e criar nós $R_{j,t}$ para $j = 1,..., J_{t}$

|    **Para** $j = 1,...,J_{t}$ **faça**:

|        $ŷ_{j,t} = \arg \min_{ŷ} \sum_{i = 1}^{n} L(y^{(i)},ŷ + h_{t-1}(x^{(i)}))$

|        atualizar o modelo $h_{t}(x) = h_{t-1}(x) + \alpha \sum_{j=1}^{J_{t}}ŷ_{j,t}$ $I(x \in R_{j,t})$

---

Para a implementação do modelo, primeiro deve-se construir um modelo $h_{0}$ base, geralmente
é utilizado a média aritmética das do valor de $y^{(i)}$. Feito isso, o próximo passo será computar
os resíduos do modelo com o objetivo de alimentar o próximo classificador. Como se trata de uma árvore
de decisão, queremos predições de cada nó que minimizem a função de custo. Por fim, é computado o somatório
das predições de cada modelo.

